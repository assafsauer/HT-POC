# SC04-TC02: Demonstrate a Self-Healing Tanzu Kubernetes Cluster

A Kubernetes node enters an errored state and becomes unresponsive. vSphere 7 with Kubernetes automatically recognizes the fault and recovers the Kubernetes cluster to the prescribed configuration

---

## Test Case Summary

This test procedure demonstrates invoking a hard, poweroff to a TKC control-plane node and monitoring the process and time for the system to restore the node's state. After restoring the control-plane node, the procedure repeats the process for a TKC worker node.

---

## Prerequisites

* SC01-TC01,SC01-TC02,SC01-TC04
* vSphere Administrator console and user credentials
* DevOps Engineer console and user credentials
* SSH service enabled on ESXi host(s)
* Root credentials to ESXi hosts (s)
* Stopwatch

---

## Test Procedure

1. Using the **DevOps Engineer** console and credentials, login to the SC API. Reference the [Configuration Supplement](../supplements/client-configuration.md##Login-to-a-Supervisor-Cluster-as-a-vCenter-Single-Sign-On-User) for details on obtaining the CLI tools and command syntax.
2. Set the context for the ns01 namespace with the command

    ```sh
    kubectl config use-context ns01
    ```

3. Identify the supporting hosts for each of the *tkc01-mm-small* cluster nodes with the following command and record the output

    ```sh
    kubectl get vm -o json | jq '.items[] | {name:.metadata.name, host:.status.host}'
    ```

4. Using the **DevOps Engineer** console and credentials, login to the TKC API. Reference the [Configuration Supplement](../supplements/client-configuration.md##-Login-to-a-Tanzu-Kubernetes-Cluster-as-a-vCenter-Single-Sign-On-User) for details on obtaining the CLI tools and command syntax.
5. Switch context to use the TKC cluster context configuration

    ```sh
    kubectl config use-context tkc01-mm-small
    ```

6. During fault testing, monitor the nodesâ€™ status from the terminal with the watch command. The watch command will routinely call the API and print the status for each node in the cluster. At this point, all nodes should report `Ready`.

    ```sh
    watch -n 10 kubectl get nodes
    ```

7. Based on the recorded output from Step 3, identify one of the *tkc01-mm-small* control-plane nodes and its respective ESXi host.

8. Using the vSphere Administrator console and credentials, login to the VC Web UI and navigate to **Menu > Host and Clusters > *vCenter_Server_Name* > *vSphere_Datacenter_Name* > *vSphere_Cluster_Name* > Namespaces > ns01 > tkc01-mm-small**. Expand **tkc01-mm-small** to list the virtual machines, select the control-plane node identified in the previous step, and in the main pane, verify the supporting host.
9. Using root credentials, open a new terminal window and initiate a SSH session to the ESXi host.
10. Identify the *tkc01-mm-small* node's VMID with the following command

    ```sh
    vim-cmd vmsvc/getallvms |grep tkc01-mm-small
    ```

11. Verify the power state of the virtual machine with the command

    <pre>vim-cmd vmsvc/power.getstate <i><b>VMID</i></b></pre>

12. Power off the virtual machine with the following command and initiate a stopwatch

    <pre>vim-cmd vmsvc/power.off <i><b>VMID</i></b></pre>

13. Return to the VC Web UI and monitor *Recent Tasks* for changes in the status of the virtual machine. Record the time it takes for the system to power back on the virtual machine.
14. From the DevOps Engineer console, monitor the terminal that is polling the *tkc01-mm-small* cluster's API for node status updates. Record the amount of time it takes for the system to detect the fault and updates the node's status to **`NotReady`**. Then, record the amount of time it takes for the system to correct the problem and restore the node's status to **`Ready`**. 
15. Stop the stopwatch and reset it.
    > Note: Do not quit the `watch -n 10 kubectl get nodes` session.
16. From the vSphere Administrator console's VC Web UI, identify one of the worker nodes in the *tkc01-mm-small* cluster and its supporting ESXi hosts. Repeat Steps 9-13.
17. From the DevOps Engineer console, monitor the terminal that is polling the *tkc01-mm-small* cluster's API for node status updates. Record the amount of time it takes for the system to detect the fault and updates the node's status to **`NotReady`**. Then, record the amount of time it takes for the system to correct the problem and restore the node's status to **`Ready`**.
18. Quit the `watch` session with the *tkc01-mm-small* and any open SSH sessions with ESXi hosts.

---

## Test Data

None

---

## Expected Results

Step | Result |
--- | --- |
6 | <pre>NAME                                            STATUS   ROLES    AGE   VERSION<br>tkc01-mm-small-control-plane-xxxxx              Ready    master   xxm   v1.16.8+vmware.1<br>tkc01-mm-small-control-plane-yyyyy              Ready    master   xxm   v1.16.8+vmware.1<br>tkc01-mm-small-control-plane-zzzzz              Ready    master   xxm   v1.16.8+vmware.1<br>tkc01-mm-small-workers-aaaaa-aaaaaaaaaa-aaaaa   Ready    none     xxm   v1.16.8+vmware.1<br>tkc01-mm-small-workers-bbbbb-bbbbbbbbbb-bbbbb   Ready    none     xxm   v1.16.8+vmware.1<br>tkc01-mm-small-workers-ccccc-cccccccccc-ccccc   Ready    none     xxm   v1.16.8+vmware.1</pre>
11 | `Powered on`
12 | `Powering off VM:`
13 | Within 180 seconds the node powers on
14 | Within 90 seconds the node status transitions to `NotReady`<br>Within 360 seconds the node status returns to `Ready`
16 | Within 600 seconds the node powers on
17 | Within 60 seconds the node status transitions to `NotReady`<br>Within 720 seconds the node status returns to `Ready`

---

## Actual Results

Step | Result |
--- | --- |
6 |  |
11 |  |
12 |  |
13 |  |
14 |  |
16 |  |
17 |  |

---

## Status Pass/Fail

* [  ] Pass
* [  ] Fail

Return to [Test Cases Inventory](../README.md#test-cases-inventory)