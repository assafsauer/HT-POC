# SC04-TC03: Demonstrate Scaling-out/in a Tanzu Kubernetes Cluster(s)

A platform operator expands the number of worker nodes for a deployed cluster and without impacting application continuity

> Note: Scaling-in TKC worker nodes is not supported in the current vSphere 7 with Kubernetes release

---

## Test Case Summary

Increasing application workload demands necessitate the ability to scale-out cluster resources capacity. A platform operator accesses the vSphere 7 with Kubernetes platform and using a single command, resizes the Kubernetes cluster with a higher number of worker nodes. The vSphere 7 with Kubernetes platform automatically builds the additional worker node VM, connects it to the respective cluster nodes network, and registers it with the cluster control plane.

---

## Prerequisites

* SC01-TC01,SC01-TC02,SC01-TC04
* DevOps Engineer console and user credentials

---

## Test Procedure

1. Using the **DevOps Engineer** console and credentials, login to the TKC API. Reference the [Configuration Supplement](../supplements/client-configuration.md##-Login-to-a-Tanzu-Kubernetes-Cluster-as-a-vCenter-Single-Sign-On-User) for details on obtaining the CLI tools and command syntax.

2. Set the context for the ns01 namespace with the command

    ```sh
    kubectl config use-context ns01
    ```

3. Review the TKC, *tkc01-mm-small*, summary information and record the current number of WORKER nodes and PHASE

    ```sh
    kubectl get tkc tkc01-mm-small
    ```

4. Describe the TKC, *tkc01-mm-small*, to identify the `Spec.Topology.Worker.Count` parameter and verify the `Node` and `Vm` components' status reports `ready`.

    ```sh
    kubectl describe tkc tkc01-mm-small 
    ```

5. Edit the `tkc tkc01-mm-small` active configuration and increase the `Spec.Topology.Worker.Count` value to **`4`**. After making the adjustment, press **[esc]`:wq`[return]** to save changes and exit the editor.

    <pre>kubectl edit tkc tkc01-mm-small <br><br>...<br>    workers:<br>      class: best-effort-small<br>      count: <b>4</b><br>...</pre>

6. Use the watch command to periodically poll the SC API and monitor the cluster scale-out process. Observe the increase to the `WORKER` count and additions to the `machine` and `virtualmachine` lists. Record the name of the new worker node. This step is complete when objects in the `machine` list report **`running`**

    ```sh
    watch -n 30 kubectl get tkc,cluster,machines,virtualmachines,events
    ```

7. Press **[control]+[c]** to end the watch session.
8. Review the TKC, *tkc01-mm-small*, summary information output and record the current number of WORKER nodes

    ```sh
    kubectl get tkc tkc01-mm-small
    ```

9. Using the **DevOps Engineer** console and credentials, login to the TKC API. Reference the [Configuration Supplement](../supplements/client-configuration.md##-Login-to-a-Tanzu-Kubernetes-Cluster-as-a-vCenter-Single-Sign-On-User) for details on obtaining the CLI tools and command syntax.

10. Switch context to use the TKC cluster context configuration

    ```sh
    kubectl config use-context tkc01-mm-small
    ```

11. List the cluster nodes with the command

    ```sh
    kubectl get nodes
    ```

12. Describe the new node and verify `Unschedulable:` **`false`**

---

## Test Data

None

---

## Expected Results

Step | Result |
--- | --- |
3 | <pre>NAME             CONTROL PLANE   WORKER   ~    PHASE<br>tkc01-mm-small   3               <b>3</b>        ~    <b>running</b></pre>
4 | All `Node` and `Vm` objects repport **`ready`**
8 | <pre>NAME             CONTROL PLANE   WORKER   ~    PHASE<br>tkc01-mm-small   3               <b>4</b>        ~    <b>running</b></pre>
11 | `Unschedulable:` **`false`**

---

## Actual Results

Step | Result |
--- | --- |
3 |  |
4 |  |
8 |  |
11 |  |

---

## Status Pass/Fail

* [  ] Pass
* [  ] Fail

Return to [Test Cases Inventory](../README.md#test-cases-inventory)